<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Intriguing Properties of Adversarial ML Attacks in the Problem Space | Turing-PHD20</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Intriguing Properties of Adversarial ML Attacks in the Problem Space" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A showcase of Turing projects across multiple student cohorts and research themes." />
<meta property="og:description" content="A showcase of Turing projects across multiple student cohorts and research themes." />
<link rel="canonical" href="https://alan-turing-institute.github.io/student-posters-2020/posters/04/" />
<meta property="og:url" content="https://alan-turing-institute.github.io/student-posters-2020/posters/04/" />
<meta property="og:site_name" content="Turing-PHD20" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-24T11:21:00+00:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://alan-turing-institute.github.io/student-posters-2020/posters/04/"},"headline":"Intriguing Properties of Adversarial ML Attacks in the Problem Space","url":"https://alan-turing-institute.github.io/student-posters-2020/posters/04/","description":"A showcase of Turing projects across multiple student cohorts and research themes.","dateModified":"2020-09-24T11:21:00+00:00","datePublished":"2020-09-24T11:21:00+00:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/student-posters-2020/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://alan-turing-institute.github.io/student-posters-2020/feed.xml" title="Turing-PHD20" /><script src="/student-posters-2020/assets/javascript/bootstrap/jquery.min.js"></script>
  <script src="/student-posters-2020/assets/javascript/bootstrap/bootstrap.bundle.min.js"></script>
</head>
<body>

    <header><nav class="navbar navbar-expand-lg navbar-dark bg-primary">
  <div class="container">
    <a class="navbar-brand" rel="author" href="/student-posters-2020/">Turing-PHD20</a>


    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        
          
            <li class="nav-item ">
              
                <a class="nav-link" href="/student-posters-2020/programme/">
                  Schedule
                </a>
              
            </li>
          
        
          
            <li class="nav-item ">
              
                <a class="nav-link" href="/student-posters-2020/guidelines/">
                  Author guidelines
                </a>
              
            </li>
          
        
      </ul>
    </div>

      <div class="navbar-brand navbar-logo mr-0 w-25 text-right overflow-hidden">
        <a href="https://www.turing.ac.uk/">
            <img src="/student-posters-2020/assets/images/turing_logo_white.webp"
                 class="align-middle img-fluid" alt="Alan Turing Institute"/>
        </a>
      </div>
    </div>
  </div>
</nav>
</header>

    <main class="py-5 container page-content">
      

<article>

	<div class="container p-4 my-4 border">
		<p class="h3">
			Intriguing Properties of Adversarial ML Attacks in the Problem Space

		</p>

		<p class = "mb-3">
			<div class="row">
				<div class = "h4 text-muted col-sm">
          
            
            <a target="_blank" href="https://www.turing.ac.uk/people/enrichment-students/feargus-pendlebury" class="passive-link">Feargus Pendlebury</a>
          
	  		</div>
			 <div class="col-sm text-muted h6 text-right">
				 Enrichment student &centerdot;
				 <a href="mailto:fpendlebury@turing.ac.uk" class="">Email</a>
			 </div>
		 </div>
		</p>

		<hr class="my-4">

		<p class="lead">
			Machine learning (ML) classifiers have demonstrated impressive performance in various domains, particularly in discriminating between malicious and benign behaviour in security-sensitive settings (e.g., malware detection, anomaly detection, code attribution, platform abuse). However, it has been shown that adversaries can attack classifiers by carefully altering input data in order to manipulate their outputs.A well-studied example of an adversarial ML attack is the evasion attack. Using a gradient-driven methodology, it’s possible to calculate an ideal perturbation δ* to apply to the original object x which will result in the target classifier misidentifying it as a different class.However, in many settings it is not possible to convert this ideal feature vector back into a real problem-space object due to the inverse feature mapping problem. In these cases, the ideal transformations required to induce δ* in x are simply not available because of various constraints that exist only in the problem-space (e.g., plausibility).In this work we clarify the relationship between feature space and problem space and propose a general formalization for problem-space attacks, including a comprehensive set of constraints to consider. This allows us to highlight the strengths and weaknesses of different approaches and better formulate novel attacks.
		</p>

		
		

		
			<a target="_blank" href="https://www.turing.ac.uk/research/research-programmes/defence-and-security" class="badge badge-pill badge-secure">Secure world</a>
		

		
			<a target="_blank" href="https://www.turing.ac.uk/research/research-programmes/tools-practices-and-systems" class="badge badge-pill badge-tools">Tools, practices and systems</a>
		

    
    
      <hr class="my-4">

		  <a target="_blank" href="/student-posters-2020/assets/posters/04-feargus-pendlebury
.pdf" role="button" aria-disabled="true" class="btn btn-dark btn-block " style="max-width:520px; white-space:nowrap; overflow:hidden;">Download poster</a>

    

    

      <hr class="my-4">

      <iframe width="560" height="315" src="https://www.youtube.com/embed/z2cqZBfSqpE
" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    

	</div>

</article>

    </main>

    <footer class="container">
<div class="py-3 border-top">
  <div class="container">

    <div class="row">

      <div class="col-sm-4">
        <p class="h5">Turing-PHD20</p>
      </div>

      <div class="col-sm-8 text-right">
        <p class="lead small">Organised by
          <a href="https://www.turing.ac.uk/people/enrichment-students/pedro-pinto-da-silva">Pedro</a>
          and
          <a href="https://www.turing.ac.uk/people/business-team/mishka-nemes">Mishka</a>
          &centerdot;
          Reach us at <a href="mailto:student-posters@turing.ac.uk">student-posters@turing.ac.uk</a>
        </p>
      </div>

    </div>

  </div>
</div>
</footer>

  </body>

</html>
